import org.apache.spark.{SparkConf, SparkContext}

object RDDOperationsDemo {
  def main(args: Array[String]): Unit = {
    // Tạo một SparkConf và SparkContext
    val conf = new SparkConf().setAppName("RDD Operations Demo")
    val sc = new SparkContext(conf)

    // Tạo một RDD từ một danh sách các số nguyên
    val data = List(1, 2, 3, 4, 5, 2, 3, 1, 6, 7)
    val rdd = sc.parallelize(data)

    // Transformation Operations
    // Map: Nhân mỗi phần tử trong RDD với 2
    val transformedRDD = rdd.map(x => x * 2)

    // Filter: Chọn các phần tử lớn hơn 2
    val filteredRDD = transformedRDD.filter(x => x > 2)

    // FlatMap: Chuyển đổi mỗi phần tử thành một hoặc nhiều phần tử
    val flatMapRDD = rdd.flatMap(x => List(x, x * 2))

    // Union: Kết hợp hai RDD thành một
    val otherData = List(8, 9, 10)
    val otherRDD = sc.parallelize(otherData)
    val unionRDD = rdd.union(otherRDD)

    // Distinct: Loại bỏ các phần tử trùng lặp
    val distinctRDD = rdd.distinct()

    // GroupByKey: Nhóm các giá trị theo key
    val pairRDD = rdd.map(x => (x % 2, x))
    val groupedRDD = pairRDD.groupByKey()

    // Actions
    // Reduce: Tính tổng các phần tử trong RDD
    val totalSum = transformedRDD.reduce((x, y) => x + y)

    // Collect: Lấy toàn bộ nội dung của RDD về máy chủ điều khiển
    val collectedData = rdd.collect()

    // Count: Đếm số lượng phần tử trong RDD
    val count = rdd.count()

    // First: Lấy phần tử đầu tiên của RDD
    val firstElement = rdd.first()

    // Take: Lấy 3 phần tử từ đầu RDD
    val takenElements = rdd.take(3)

    // Hiển thị kết quả
    println(s"Original RDD: ${collectedData.mkString(", ")}")
    println(s"Transformed RDD (multiplied by 2): ${transformedRDD.collect().mkString(", ")}")
    println(s"Filtered RDD (greater than 2): ${filteredRDD.collect().mkString(", ")}")
    println(s"FlatMap RDD: ${flatMapRDD.collect().mkString(", ")}")
    println(s"Union RDD: ${unionRDD.collect().mkString(", ")}")
    println(s"Distinct RDD: ${distinctRDD.collect().mkString(", ")}")
    println(s"Grouped RDD: ${groupedRDD.collect().mkString(", ")}")
    println(s"Total sum of transformed RDD: $totalSum")
    println(s"Count of elements in the original RDD: $count")
    println(s"First element of the RDD: $firstElement")
    println(s"Taken elements from the RDD: ${takenElements.mkString(", ")}")

    // Đóng SparkContext
    sc.stop()
  }
}